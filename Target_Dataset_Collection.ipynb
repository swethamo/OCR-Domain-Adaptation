{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code to extract individual handwritten words from a page of words (clearly written with enough spacing between words) and output it into a folder for further processing"
      ],
      "metadata": {
        "id": "BfLhMJXi5IBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s0aGNvmrQz6",
        "outputId": "878d9226-36f3-4d70-b45c-fba971c603bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def extract_words(image_path, output_folder):\n",
        "    # Read the image\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Thresholding the image (invert and binary threshold)\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Dilation: increase the size of the contours to merge letters into words\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 10))  # Larger horizontal kernel\n",
        "    dilated = cv2.dilate(thresh, kernel, iterations=2)  # Increase iterations to merge contours more\n",
        "\n",
        "    # Find contours in the dilated image\n",
        "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Sort contours by x-coordinate (left to right order)\n",
        "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
        "\n",
        "    # Create output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    word_count = 0\n",
        "    for contour in contours:\n",
        "        # Get bounding box for each word (or part of a word)\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "        # Filter out small contours that are unlikely to be words\n",
        "        if w > 50 and h > 15:  # You may need to adjust these values for your handwriting\n",
        "            word_count += 1\n",
        "            word_image = img[y:y+h, x:x+w]\n",
        "\n",
        "            # Save the word image\n",
        "            output_path = os.path.join(output_folder, f\"word_{word_count}.png\")\n",
        "            cv2.imwrite(output_path, word_image)\n",
        "\n",
        "    print(f\"Extracted {word_count} words and saved in '{output_folder}'.\")\n",
        "\n",
        "# Example usage\n",
        "extract_words(\"/content/gdrive/MyDrive/Neural/pages/Already Loaded Pages/page 27.jpeg\",\n",
        "              \"/content/gdrive/MyDrive/Neural/pages/words13\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTkZ3x7cxVHg",
        "outputId": "fbfb0cd9-2062-43f7-e119-f4bfb72f7cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 38 words and saved in '/content/gdrive/MyDrive/Neural/pages/words13'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TQq21CU3cQZb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}